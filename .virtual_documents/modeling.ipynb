
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, ConfusionMatrixDisplay
from sklearn.preprocessing import StandardScaler

from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression


df = pd.read_csv('./data/cleaned_wine.csv')





df.value_counts('wine', normalize=True)





X = df.drop(columns=['wine'])
y = df['wine']
scaler = StandardScaler()


X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.25, stratify=y)


X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)








knn = KNeighborsClassifier()


param_grid = {
    'n_neighbors': np.arange(3, 31, 2),
    'weights': ['uniform', 'distance'],
    'metric': ['minkowski', 'manhattan']
}


grid_knn = GridSearchCV(knn, param_grid, cv=3)


grid_knn.fit(X_train_scaled, y_train)


grid_knn.score(X_test_scaled, y_test)


grid_knn.best_params_


best_knn = grid_knn.best_estimator_


knn_pred = best_knn.predict(X_test_scaled)


print(classification_report(y_test, knn_pred))


ConfusionMatrixDisplay.from_estimator(best_knn, X_test_scaled, y_test, cmap='Blues')








rf = RandomForestClassifier(random_state=42)


rf.fit(X_train, y_train)


rf.score(X_test, y_test)


rf_preds = rf.predict(X_test)


print(classification_report(y_test, rf_preds))


ConfusionMatrixDisplay.from_estimator(rf, X_test, y_test, cmap='Blues')








logreg = LogisticRegression()



logreg.fit(X_train_scaled, y_train)



logreg.score(X_test_scaled, y_test)


log_pred = logreg.predict(X_test_scaled)



print(classification_report(y_test, log_pred))



ConfusionMatrixDisplay.from_estimator(logreg, X_test_scaled, y_test, cmap='Blues')














import pickle


with open('model.pkl', 'wb') as file:
    pickle.dump(rf, file)



